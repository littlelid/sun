{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import scipy.io as sio  \n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import os, sys\n",
    "import math\n",
    "import seaborn\n",
    "from data_buffer import Data_buffer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of csi 1: 37233  len of csi 0: 36204\n"
     ]
    }
   ],
   "source": [
    "window_size = 8\n",
    "data_buffer = Data_buffer(window_size=window_size)\n",
    "csi1_filename = '/Users/wangweiguo/Desktop/zigfi/python_data/wifi10/dis15pow23.mat'\n",
    "csi0_filename = '/Users/wangweiguo/Desktop/zigfi/python_data/wifi10/dis1air2.mat'\n",
    "data_buffer.load_csi_from_file(csi1_filename, csi0_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 49.095965130\n",
      "test  Accuracy: 0.730055\n",
      "train  Accuracy: 0.6742\n",
      "Epoch: 0002 cost= 9.398109930\n",
      "Epoch: 0003 cost= 5.260684211\n",
      "Epoch: 0004 cost= 3.669836573\n",
      "Epoch: 0005 cost= 2.942551659\n",
      "Epoch: 0006 cost= 2.411616722\n",
      "Epoch: 0007 cost= 2.056823130\n",
      "Epoch: 0008 cost= 1.733831188\n",
      "Epoch: 0009 cost= 1.518672422\n",
      "Epoch: 0010 cost= 1.424180157\n",
      "Epoch: 0011 cost= 1.279405118\n",
      "test  Accuracy: 0.899454\n",
      "train  Accuracy: 0.879\n",
      "Epoch: 0012 cost= 1.151692718\n",
      "Epoch: 0013 cost= 1.033336243\n",
      "Epoch: 0014 cost= 0.944934906\n",
      "Epoch: 0015 cost= 0.872401594\n",
      "Epoch: 0016 cost= 0.790743941\n",
      "Epoch: 0017 cost= 0.713629167\n",
      "Epoch: 0018 cost= 0.674288374\n",
      "Epoch: 0019 cost= 0.638247419\n",
      "Epoch: 0020 cost= 0.566647197\n",
      "Epoch: 0021 cost= 0.557876552\n",
      "test  Accuracy: 0.944262\n",
      "train  Accuracy: 0.9248\n",
      "Epoch: 0022 cost= 0.541989679\n",
      "Epoch: 0023 cost= 0.479453908\n",
      "Epoch: 0024 cost= 0.478498713\n",
      "Epoch: 0025 cost= 0.433897971\n",
      "Epoch: 0026 cost= 0.409236842\n",
      "Epoch: 0027 cost= 0.401947708\n",
      "Epoch: 0028 cost= 0.373489356\n",
      "Epoch: 0029 cost= 0.350977470\n",
      "Epoch: 0030 cost= 0.334746172\n",
      "Epoch: 0031 cost= 0.323525241\n",
      "test  Accuracy: 0.956284\n",
      "train  Accuracy: 0.9356\n",
      "Epoch: 0032 cost= 0.330022255\n",
      "Epoch: 0033 cost= 0.315007373\n",
      "Epoch: 0034 cost= 0.304151107\n",
      "Epoch: 0035 cost= 0.265847125\n",
      "Epoch: 0036 cost= 0.268521236\n",
      "Epoch: 0037 cost= 0.260925181\n",
      "Epoch: 0038 cost= 0.241279844\n",
      "Epoch: 0039 cost= 0.235600967\n",
      "Epoch: 0040 cost= 0.213216604\n",
      "Epoch: 0041 cost= 0.219491038\n",
      "test  Accuracy: 0.963934\n",
      "train  Accuracy: 0.957\n",
      "Epoch: 0042 cost= 0.210683749\n",
      "Epoch: 0043 cost= 0.213063668\n",
      "Epoch: 0044 cost= 0.196843956\n",
      "Epoch: 0045 cost= 0.189046401\n",
      "Epoch: 0046 cost= 0.210355077\n",
      "Epoch: 0047 cost= 0.178688521\n",
      "Epoch: 0048 cost= 0.184224102\n",
      "Epoch: 0049 cost= 0.183988931\n",
      "Epoch: 0050 cost= 0.173975429\n",
      "Epoch: 0051 cost= 0.190497012\n",
      "test  Accuracy: 0.963934\n",
      "train  Accuracy: 0.9578\n",
      "Epoch: 0052 cost= 0.157632167\n",
      "Epoch: 0053 cost= 0.156392957\n",
      "Epoch: 0054 cost= 0.152669992\n",
      "Epoch: 0055 cost= 0.139446015\n",
      "Epoch: 0056 cost= 0.155330689\n",
      "Epoch: 0057 cost= 0.151272418\n",
      "Epoch: 0058 cost= 0.138990977\n",
      "Epoch: 0059 cost= 0.130107951\n",
      "Epoch: 0060 cost= 0.137093019\n",
      "Epoch: 0061 cost= 0.128277966\n",
      "test  Accuracy: 0.970492\n",
      "train  Accuracy: 0.9704\n",
      "Epoch: 0062 cost= 0.128554762\n",
      "Epoch: 0063 cost= 0.119274186\n",
      "Epoch: 0064 cost= 0.148651183\n",
      "Epoch: 0065 cost= 0.118806039\n",
      "Epoch: 0066 cost= 0.113419694\n",
      "Epoch: 0067 cost= 0.110701802\n",
      "Epoch: 0068 cost= 0.104509129\n",
      "Epoch: 0069 cost= 0.111505633\n",
      "Epoch: 0070 cost= 0.104183415\n",
      "Epoch: 0071 cost= 0.112350090\n",
      "test  Accuracy: 0.977049\n",
      "train  Accuracy: 0.9764\n",
      "Epoch: 0072 cost= 0.102948517\n",
      "Epoch: 0073 cost= 0.111265805\n",
      "Epoch: 0074 cost= 0.093389414\n",
      "Epoch: 0075 cost= 0.098206048\n",
      "Epoch: 0076 cost= 0.095313012\n",
      "Epoch: 0077 cost= 0.098088756\n",
      "Epoch: 0078 cost= 0.092427234\n",
      "Epoch: 0079 cost= 0.096659968\n",
      "Epoch: 0080 cost= 0.087745774\n",
      "Epoch: 0081 cost= 0.092585242\n",
      "test  Accuracy: 0.975956\n",
      "train  Accuracy: 0.9786\n",
      "Epoch: 0082 cost= 0.078836464\n",
      "Epoch: 0083 cost= 0.083605310\n",
      "Epoch: 0084 cost= 0.087557230\n",
      "Epoch: 0085 cost= 0.089462444\n",
      "Epoch: 0086 cost= 0.100792134\n",
      "Epoch: 0087 cost= 0.080470522\n",
      "Epoch: 0088 cost= 0.079397050\n",
      "Epoch: 0089 cost= 0.083357734\n",
      "Epoch: 0090 cost= 0.078289129\n",
      "Epoch: 0091 cost= 0.071320778\n",
      "test  Accuracy: 0.97377\n",
      "train  Accuracy: 0.9806\n",
      "Epoch: 0092 cost= 0.066164847\n",
      "Epoch: 0093 cost= 0.063253660\n",
      "Epoch: 0094 cost= 0.067588230\n",
      "Epoch: 0095 cost= 0.072955783\n",
      "Epoch: 0096 cost= 0.063518592\n",
      "Epoch: 0097 cost= 0.075908997\n",
      "Epoch: 0098 cost= 0.065166288\n",
      "Epoch: 0099 cost= 0.060022970\n",
      "Epoch: 0100 cost= 0.065047286\n",
      "Epoch: 0101 cost= 0.057853698\n",
      "test  Accuracy: 0.97377\n",
      "train  Accuracy: 0.983\n",
      "Epoch: 0102 cost= 0.057536732\n",
      "Epoch: 0103 cost= 0.055148468\n",
      "Epoch: 0104 cost= 0.058828651\n",
      "Epoch: 0105 cost= 0.051575931\n",
      "Epoch: 0106 cost= 0.063258764\n",
      "Epoch: 0107 cost= 0.059860949\n",
      "Epoch: 0108 cost= 0.060945596\n",
      "Epoch: 0109 cost= 0.050676902\n",
      "Epoch: 0110 cost= 0.055385363\n",
      "Epoch: 0111 cost= 0.054021591\n",
      "test  Accuracy: 0.983607\n",
      "train  Accuracy: 0.9836\n",
      "Epoch: 0112 cost= 0.061538736\n",
      "Epoch: 0113 cost= 0.050248381\n",
      "Epoch: 0114 cost= 0.054584384\n",
      "Epoch: 0115 cost= 0.056246858\n",
      "Epoch: 0116 cost= 0.051285102\n",
      "Epoch: 0117 cost= 0.054252903\n",
      "Epoch: 0118 cost= 0.046399257\n",
      "Epoch: 0119 cost= 0.044697077\n",
      "Epoch: 0120 cost= 0.047047548\n",
      "Epoch: 0121 cost= 0.050643311\n",
      "test  Accuracy: 0.981421\n",
      "train  Accuracy: 0.9838\n",
      "Epoch: 0122 cost= 0.048115886\n",
      "Epoch: 0123 cost= 0.042956964\n",
      "Epoch: 0124 cost= 0.044386135\n",
      "Epoch: 0125 cost= 0.049887972\n",
      "Epoch: 0126 cost= 0.042007831\n",
      "Epoch: 0127 cost= 0.043981062\n",
      "Epoch: 0128 cost= 0.040518348\n",
      "Epoch: 0129 cost= 0.044441509\n",
      "Epoch: 0130 cost= 0.045234090\n",
      "Epoch: 0131 cost= 0.040997256\n",
      "test  Accuracy: 0.982514\n",
      "train  Accuracy: 0.9858\n",
      "Epoch: 0132 cost= 0.038351874\n",
      "Epoch: 0133 cost= 0.044580236\n",
      "Epoch: 0134 cost= 0.042995447\n",
      "Epoch: 0135 cost= 0.042464281\n",
      "Epoch: 0136 cost= 0.037460448\n",
      "Epoch: 0137 cost= 0.043008346\n",
      "Epoch: 0138 cost= 0.041316756\n",
      "Epoch: 0139 cost= 0.039414915\n",
      "Epoch: 0140 cost= 0.040828837\n",
      "Epoch: 0141 cost= 0.032956273\n",
      "test  Accuracy: 0.977049\n",
      "train  Accuracy: 0.988\n",
      "Epoch: 0142 cost= 0.042174040\n",
      "Epoch: 0143 cost= 0.036198076\n",
      "Epoch: 0144 cost= 0.036644956\n",
      "Epoch: 0145 cost= 0.036821204\n",
      "Epoch: 0146 cost= 0.033557343\n",
      "Epoch: 0147 cost= 0.041724039\n",
      "Epoch: 0148 cost= 0.040059156\n",
      "Epoch: 0149 cost= 0.030638370\n",
      "Epoch: 0150 cost= 0.036896244\n",
      "Epoch: 0151 cost= 0.027208121\n",
      "test  Accuracy: 0.987978\n",
      "train  Accuracy: 0.9884\n",
      "Epoch: 0152 cost= 0.030115646\n",
      "Epoch: 0153 cost= 0.036228386\n",
      "Epoch: 0154 cost= 0.032881430\n",
      "Epoch: 0155 cost= 0.032743779\n",
      "Epoch: 0156 cost= 0.031964177\n",
      "Epoch: 0157 cost= 0.036212660\n",
      "Epoch: 0158 cost= 0.036383487\n",
      "Epoch: 0159 cost= 0.035387117\n",
      "Epoch: 0160 cost= 0.030143631\n",
      "Epoch: 0161 cost= 0.032810490\n",
      "test  Accuracy: 0.978142\n",
      "train  Accuracy: 0.9902\n",
      "Epoch: 0162 cost= 0.033594845\n",
      "Epoch: 0163 cost= 0.028078158\n",
      "Epoch: 0164 cost= 0.035013691\n",
      "Epoch: 0165 cost= 0.032937512\n",
      "Epoch: 0166 cost= 0.032553938\n",
      "Epoch: 0167 cost= 0.032076971\n",
      "Epoch: 0168 cost= 0.028198817\n",
      "Epoch: 0169 cost= 0.033196240\n",
      "Epoch: 0170 cost= 0.032014096\n",
      "Epoch: 0171 cost= 0.034206855\n",
      "test  Accuracy: 0.987978\n",
      "train  Accuracy: 0.9892\n",
      "Epoch: 0172 cost= 0.029322440\n",
      "Epoch: 0173 cost= 0.035431737\n",
      "Epoch: 0174 cost= 0.031124710\n",
      "Epoch: 0175 cost= 0.029278438\n",
      "Epoch: 0176 cost= 0.031029543\n",
      "Epoch: 0177 cost= 0.029141135\n",
      "Epoch: 0178 cost= 0.031886464\n",
      "Epoch: 0179 cost= 0.031365652\n",
      "Epoch: 0180 cost= 0.027685466\n",
      "Epoch: 0181 cost= 0.030463366\n",
      "test  Accuracy: 0.986885\n",
      "train  Accuracy: 0.9886\n",
      "Epoch: 0182 cost= 0.030372626\n",
      "Epoch: 0183 cost= 0.026907844\n",
      "Epoch: 0184 cost= 0.026255117\n",
      "Epoch: 0185 cost= 0.030472445\n",
      "Epoch: 0186 cost= 0.028243096\n",
      "Epoch: 0187 cost= 0.024402819\n",
      "Epoch: 0188 cost= 0.023630812\n",
      "Epoch: 0189 cost= 0.029112856\n",
      "Epoch: 0190 cost= 0.025555821\n",
      "Epoch: 0191 cost= 0.025464341\n",
      "test  Accuracy: 0.984699\n",
      "train  Accuracy: 0.9894\n",
      "Epoch: 0192 cost= 0.027765400\n",
      "Epoch: 0193 cost= 0.022988880\n",
      "Epoch: 0194 cost= 0.024383217\n",
      "Epoch: 0195 cost= 0.026147301\n",
      "Epoch: 0196 cost= 0.022969516\n",
      "Epoch: 0197 cost= 0.026309376\n",
      "Epoch: 0198 cost= 0.028103555\n",
      "Epoch: 0199 cost= 0.026091538\n",
      "Epoch: 0200 cost= 0.020581701\n",
      "Epoch: 0201 cost= 0.023980558\n",
      "test  Accuracy: 0.985792\n",
      "train  Accuracy: 0.9904\n",
      "Epoch: 0202 cost= 0.028452597\n",
      "Epoch: 0203 cost= 0.022965525\n",
      "Epoch: 0204 cost= 0.024241144\n",
      "Epoch: 0205 cost= 0.024118467\n",
      "Epoch: 0206 cost= 0.026803055\n",
      "Epoch: 0207 cost= 0.029790035\n",
      "Epoch: 0208 cost= 0.026954373\n",
      "Epoch: 0209 cost= 0.025203510\n",
      "Epoch: 0210 cost= 0.025409865\n",
      "Epoch: 0211 cost= 0.023056051\n",
      "test  Accuracy: 0.974863\n",
      "train  Accuracy: 0.9884\n",
      "Epoch: 0212 cost= 0.026457023\n",
      "Epoch: 0213 cost= 0.022918063\n",
      "Epoch: 0214 cost= 0.021716531\n",
      "Epoch: 0215 cost= 0.025035160\n",
      "Epoch: 0216 cost= 0.024927117\n",
      "Epoch: 0217 cost= 0.022458797\n",
      "Epoch: 0218 cost= 0.023626432\n",
      "Epoch: 0219 cost= 0.019614249\n",
      "Epoch: 0220 cost= 0.023330408\n",
      "Epoch: 0221 cost= 0.026355239\n",
      "test  Accuracy: 0.981421\n",
      "train  Accuracy: 0.9886\n",
      "Epoch: 0222 cost= 0.021651459\n",
      "Epoch: 0223 cost= 0.025787175\n",
      "Epoch: 0224 cost= 0.025377743\n",
      "Epoch: 0225 cost= 0.023056510\n",
      "Epoch: 0226 cost= 0.023994363\n",
      "Epoch: 0227 cost= 0.026997304\n",
      "Epoch: 0228 cost= 0.024898929\n",
      "Epoch: 0229 cost= 0.026638973\n",
      "Epoch: 0230 cost= 0.021891030\n",
      "Epoch: 0231 cost= 0.021370572\n",
      "test  Accuracy: 0.99235\n",
      "train  Accuracy: 0.9896\n",
      "Epoch: 0232 cost= 0.022841522\n",
      "Epoch: 0233 cost= 0.024834371\n",
      "Epoch: 0234 cost= 0.027184421\n",
      "Epoch: 0235 cost= 0.024683497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0236 cost= 0.024175863\n",
      "Epoch: 0237 cost= 0.022069671\n",
      "Epoch: 0238 cost= 0.020131623\n",
      "Epoch: 0239 cost= 0.022080873\n",
      "Epoch: 0240 cost= 0.023958666\n",
      "Epoch: 0241 cost= 0.023230370\n",
      "test  Accuracy: 0.986885\n",
      "train  Accuracy: 0.989\n",
      "Epoch: 0242 cost= 0.025163232\n",
      "Epoch: 0243 cost= 0.019644607\n",
      "Epoch: 0244 cost= 0.021490057\n",
      "Epoch: 0245 cost= 0.019635959\n",
      "Epoch: 0246 cost= 0.021114505\n",
      "Epoch: 0247 cost= 0.020744846\n",
      "Epoch: 0248 cost= 0.022062035\n",
      "Epoch: 0249 cost= 0.018822665\n",
      "Epoch: 0250 cost= 0.023828126\n",
      "Epoch: 0251 cost= 0.022884631\n",
      "test  Accuracy: 0.980328\n",
      "train  Accuracy: 0.992\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2d55fafe9496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             _, c = sess.run([optimizer, cost], feed_dict={x: batch_X, \n\u001b[1;32m     72\u001b[0m                                                           y: batch_y})\n",
      "\u001b[0;32m~/sun_repo/sun/data/data_buffer.py\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, batch_size, one_zero_rate)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mbatch_csi_bit1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsi_bit1_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mbatch_csi_bit1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_csi_bit1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1fec32e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 设置模型参数\n",
    "learning_rate = 0.001\n",
    "training_epochs = 500\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "n_sample = int( len(data_buffer.csi_bit1_train)/8 + len(data_buffer.csi_bit0_train)/8 )\n",
    "\n",
    "n_input = window_size\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 64\n",
    "n_hidden_3 = 32\n",
    "n_class = 2\n",
    "\n",
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_class])\n",
    "\n",
    "\n",
    "def multiplayer_perceptron(x, weight, bias):\n",
    "    layer1 = tf.add(tf.matmul(x, weight['h1']), bias['h1'])\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    layer2 = tf.add(tf.matmul(layer1, weight['h2']), bias['h2'])\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    layer3 = tf.add(tf.matmul(layer2, weight['h3']), bias['h3'])\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "    out_layer = tf.add(tf.matmul(layer3, weight['out']), bias['out'])\n",
    "    out_layer = tf.nn.dropout(out_layer, keep_prob=0.9)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "weight = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), \n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])), \n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_3, n_class]))\n",
    "}\n",
    "bias = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_2])), \n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_3])), \n",
    "    'out': tf.Variable(tf.random_normal([n_class]))\n",
    "}\n",
    "\n",
    "# 建立模型\n",
    "pred = multiplayer_perceptron(x, weight, bias)\n",
    "\n",
    "# 定义损失函数\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "# 优化\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# 初始化所有变量\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "# 训练模型\n",
    "test_step = 100\n",
    "X_test, y_test = data_buffer.get_test_set()\n",
    "X_train, y_train = data_buffer.get_train_set()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(n_sample / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_X, batch_y = data_buffer.next_batch()\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_X, \n",
    "                                                          y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        plt.plot(epoch+1, avg_cost, 'co')\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print('Epoch:', '%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "        if epoch % 10 == 0:\n",
    "            acc = accuracy.eval({x: X_test, y: y_test})\n",
    "            print('test  Accuracy:', acc)\n",
    "            acc = accuracy.eval({x: X_train, y: y_train})\n",
    "            print('train  Accuracy:', acc)\n",
    "    print('Opitimization Finished!')\n",
    "    # Test\n",
    "    acc = accuracy.eval({x: X_test, y: y_test})\n",
    "    print('test  Accuracy:', acc)\n",
    "    #acc = accuracy.eval({x: X_train, y: y_train})\n",
    "    #print('train Accuracy:', acc)\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('lr=%f, te=%d, bs=%d, acc=%f' % (learning_rate, training_epochs, batch_size, acc))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
